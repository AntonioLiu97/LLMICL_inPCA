{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up directory\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Check if directory exists, if not create it\n",
    "save_path = os.path.join(parent_dir, 'generated_series')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from data.serialize import serialize_arr, deserialize_str, SerializerSettings\n",
    "import pickle\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "def serialize_gaussian(prec, time_series, mean_series, sigma_series, rescale_factor = 0.7, up_shift = 0.15, span = None):\n",
    "    \"\"\"\n",
    "    Serialize a time series with gaussian noise and continuous support.\n",
    "    span: range of raw time series\n",
    "\n",
    "    Parameters:\n",
    "    prec (int): Precision of the serialization\n",
    "    time_series (list): The time series data\n",
    "    mean_series (list): The mean series data\n",
    "    sigma_series (list): The sigma series data\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing \n",
    "        serialized time series: str\n",
    "        rescaled mean series: np array\n",
    "        rescaled sigma series: np array\n",
    "    \"\"\"\n",
    "    settings=SerializerSettings(base=10, prec=prec, signed=True, time_sep=',', bit_sep='', minus_sign='-', fixed_length=False, max_val = 10)\n",
    "    time_series = np.array(time_series)\n",
    "    ### Final range is from 0.15 to 0.85\n",
    "\n",
    "    if span is None:\n",
    "        span = time_series.max()-time_series.min()\n",
    "        \n",
    "    rescaled_array = (time_series-time_series.min())/span * rescale_factor + up_shift\n",
    "    rescaled_true_mean_arr = (np.array(mean_series)-time_series.min())/span * rescale_factor + up_shift\n",
    "    rescaled_true_sigma_arr = np.array(sigma_series)/span * rescale_factor \n",
    "    rescaled_true_mean_arr *= 10\n",
    "    rescaled_true_sigma_arr *= 10\n",
    "    rescaled_full_series = 10*rescaled_array\n",
    "    # print(rescaled_array)\n",
    "    assert all(rescaled_array >= 0) and all(rescaled_array <= 1), \"Elements in rescaled_array should be between 0 and 1\"\n",
    "    # print(min(rescaled_array))\n",
    "    full_series = serialize_arr(rescaled_array, settings)\n",
    "    return (rescaled_full_series, full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr)\n",
    "\n",
    "def generate_transition_matrix(N_state):\n",
    "    \"\"\"\n",
    "    Generate a random transition matrix of shape (N_state, N_state).\n",
    "    Each row sums to 1.\n",
    "    \"\"\"\n",
    "    P = np.random.rand(N_state, N_state)\n",
    "    P /= P.sum(axis=1)[:, np.newaxis]\n",
    "    return P\n",
    "\n",
    "def generate_gaussian_matrix(N_state, sigma = 0.5):\n",
    "    \"\"\"\n",
    "    Generate a transition matrix of shape (N_state, N_state) for an uncorrelated Brownian motion.\n",
    "    Each row will be the same, representing discretized bins of a Gaussian distribution.\n",
    "    The sum of each row is normalized to 1.\n",
    "\n",
    "    :param N_state: Number of states (and thus size of the transition matrix)\n",
    "    :param sigma: Standard deviation of the Gaussian distribution (controls the width of the Gaussian)\n",
    "    \"\"\"\n",
    "    # Define the bins for the Gaussian distribution\n",
    "    bins = np.linspace(-3, 3, N_state)\n",
    "    \n",
    "    # Calculate the Gaussian distribution values for these bins\n",
    "    gaussian_distribution = np.exp(-0.5 * (bins / sigma) ** 2)\n",
    "    gaussian_distribution /= gaussian_distribution.sum()  # Normalize to sum to 1\n",
    "\n",
    "    # Repeat this distribution for each row to create the transition matrix\n",
    "    P = np.tile(gaussian_distribution, (N_state, 1))\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Series with Continuous Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = 2\n",
    "llama_size = '70b'\n",
    "\n",
    "mode = 'all'\n",
    "prec = 2\n",
    "refine_depth = 1\n",
    "\n",
    "kernel = 'NA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = 2\n",
    "llama_size = 'KDE'\n",
    "kernel = 'gaussian'\n",
    "\n",
    "mode = 'all'\n",
    "prec = 2\n",
    "refine_depth = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = 2\n",
    "llama_size = 'histogram'\n",
    "kernel = 'NA'\n",
    "\n",
    "mode = 'all'\n",
    "prec = 2\n",
    "refine_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Uncorrelated Gaussian'\n",
    "sigma = 0.5\n",
    "# sigma = 0.8\n",
    "# sigma = 0.1\n",
    "# sigma = 0.3\n",
    "Nt = 400\n",
    "traj_name = f'uncorrelated_gaussian_centered_sigma_{sigma}_{llama_size}'\n",
    "\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx+2\n",
    "    np.random.seed(random_seed)\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "    for t in range(0, Nt):\n",
    "        W =  np.random.normal() * sigma \n",
    "        \n",
    "        time_series.append(W)\n",
    "        mean_series.append(0)\n",
    "        sigma_series.append(sigma)\n",
    "    \n",
    "    rescale_factor = 0.2\n",
    "    span = 0.2*7\n",
    "    up_shift = 0.5 + min(time_series)/span*rescale_factor\n",
    "    \n",
    "    rescaled_full_series, full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series, rescale_factor = rescale_factor, up_shift = up_shift, span = span)\n",
    "    # print(max(time_series)-min(time_series))\n",
    "    # print(rescaled_true_sigma_arr[1])    \n",
    "    # print(rescaled_true_mean_arr[1])    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot((np.array(time_series)-min(time_series))/span*rescale_factor+up_shift, lw = 0, marker = 'o', alpha = 1)\n",
    "    plt.ylim(0,1)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series, # string format for LLM\n",
    "            'rescaled_full_series': rescaled_full_series, # double format for baseline\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'kernel': kernel,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncorrelated uniform dist.\n",
    "# for uniform distribution, sigma = half width\n",
    "# sigma = 0.8\n",
    "# sigma = 0.5\n",
    "# sigma = 0.3\n",
    "sigma = 0.1\n",
    "Nt = 400\n",
    "traj_name = f'uncorrelated_uniform_centered_sigma_{sigma}'\n",
    "\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx+2\n",
    "    np.random.seed(random_seed)\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "    for t in range(0, Nt):\n",
    "        W =  np.random.uniform(low=-sigma, high=sigma)\n",
    "        \n",
    "        time_series.append(W)\n",
    "        mean_series.append(0)\n",
    "        sigma_series.append(sigma)\n",
    "    \n",
    "    rescale_factor = 0.5\n",
    "    span = 0.2*7\n",
    "    up_shift = 0.5 + min(time_series)/span*rescale_factor\n",
    "    \n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series, rescale_factor = rescale_factor, up_shift = up_shift, span = span)  \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot((np.array(time_series)-min(time_series))/span*rescale_factor+up_shift, lw = 0, marker = 'o', alpha = 1)\n",
    "    plt.ylim(0,1)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'dist type': \"uniform\",\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "### Generate continuous time series\n",
    "####################################\n",
    "\n",
    "### Brownian Motion\n",
    "\n",
    "\n",
    "\n",
    "traj_name = 'brownian_motion'\n",
    "Nt = 1000 # number of steps\n",
    "a = 0 # drift\n",
    "\n",
    "# other hyper-parameters\n",
    "dt =  0.2 # time step\n",
    "tspan = np.linspace(0, Nt*dt, Nt)\n",
    "sigma = 0.8\n",
    "\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = 7+traj_idx\n",
    "    print(\"random_seed: \", random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    # Initialize the time series\n",
    "    x = 0  # Starting point\n",
    "    time_series = [x]\n",
    "    mean_series = [x]\n",
    "    sigma_series = [0]\n",
    "\n",
    "    # Generate the drift-diffusion time series\n",
    "    for t in range(1, Nt):\n",
    "        x_mean = x + a*dt\n",
    "        x_sigma = sigma * np.sqrt(dt)\n",
    "        dW =  np.random.normal()  # Wiener process (Brownian motion)\n",
    "        x = x_mean + x_sigma * dW\n",
    "        \n",
    "        time_series.append(x)\n",
    "        mean_series.append(x_mean)\n",
    "        sigma_series.append(x_sigma)\n",
    "        \n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(time_series, alpha = 1)\n",
    "\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "        'full_series': full_series,\n",
    "        'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "        'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "        'prec': prec,\n",
    "        'llama_size': llama_size,\n",
    "        'mode': mode,\n",
    "        'refine_depth': refine_depth,\n",
    "        'random_seed': random_seed,\n",
    "        'time_series': np.array(time_series)\n",
    "    }\n",
    "\n",
    "    # Pickle and save the dictionary\n",
    "    # Count existing files in the save_path and assign a new number\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "traj_name = 'correlated_gaussian'\n",
    "Nt = 1000 # number of steps\n",
    "a = 0 # drift\n",
    "theta = 0.5 # restoring spring constant\n",
    "\n",
    "# other hyper-parameters\n",
    "dt =  0.2 # time step\n",
    "tspan = np.linspace(0, Nt*dt, Nt)\n",
    "sigma = 0.8\n",
    "\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx\n",
    "    print(\"random_seed: \", random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    # Initialize the time series\n",
    "    x = 0  # Starting point\n",
    "    time_series = [x]\n",
    "    mean_series = [x]\n",
    "    sigma_series = [0]\n",
    "\n",
    "    # Generate the drift-diffusion time series\n",
    "    for t in range(1, Nt):\n",
    "        x_mean = x + a*dt - x * theta*dt\n",
    "        x_sigma = sigma * np.sqrt(dt)\n",
    "        dW =  np.random.normal()  # Wiener process (Brownian motion)\n",
    "        x = x_mean + x_sigma * dW\n",
    "        \n",
    "        time_series.append(x)\n",
    "        mean_series.append(x_mean)\n",
    "        sigma_series.append(x_sigma)\n",
    "        \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time_series, alpha = 1)\n",
    "\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "        'full_series': full_series,\n",
    "        'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "        'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "        'prec': prec,\n",
    "        'llama_size': llama_size,\n",
    "        'mode': mode,\n",
    "        'refine_depth': refine_depth,\n",
    "        'random_seed': random_seed,\n",
    "        'time_series': np.array(time_series)\n",
    "    }\n",
    "\n",
    "    # Pickle and save the dictionary\n",
    "    # Count existing files in the save_path and assign a new number\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gemetric Brownian Motion\n",
    "traj_name = 'geometric_brownian_motion'\n",
    "# hyper-parameter to load from json\n",
    "\n",
    "\n",
    "Nt = 1000 # number of steps\n",
    "sigma = 0.6\n",
    "a = None\n",
    "\n",
    "if a is None:\n",
    "    a = sigma**2/2\n",
    "    \n",
    "dt =  0.2 # time step\n",
    "tspan = np.linspace(1, Nt*dt, Nt)\n",
    "\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx+2\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Initialize the time series\n",
    "    x = 10  # Starting point\n",
    "    time_series = [x]\n",
    "    mean_series = [x]\n",
    "    sigma_series = [0]\n",
    "\n",
    "    # Generate the drift-diffusion time series\n",
    "    for t in range(1, Nt):\n",
    "        x_mean = x + a*dt\n",
    "        x_sigma = x * sigma * np.sqrt(dt)\n",
    "        dW =  np.random.normal()  # Wiener process (Brownian motion)\n",
    "        x = x_mean + x_sigma * dW\n",
    "        \n",
    "        time_series.append(x)\n",
    "        mean_series.append(x_mean)\n",
    "        sigma_series.append(x_sigma)\n",
    "        \n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(time_series, alpha = 1)\n",
    "    # plt.yscale('log')\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "        # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "\n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Noisy Logistic Map\n",
    "traj_name = 'noisy_logistic_map'\n",
    "# hyper-parameter to load from json\n",
    "\n",
    "\n",
    "Nt = 1000\n",
    "sigma = 0.0136\n",
    "r = 3.9\n",
    "\n",
    "### Logistic Map\n",
    "def logistic_map(r, x):\n",
    "    return r * x * (1 - x)\n",
    "\n",
    "### Manual differentiation\n",
    "def logistic_map_diff(r, x):\n",
    "    return np.abs(r * (1-2*x))\n",
    "\n",
    "counter = -1\n",
    "traj_idx = 3\n",
    "while counter < num_series-1:\n",
    "    random_seed = traj_idx\n",
    "    np.random.seed(random_seed)\n",
    "    traj_idx += 1\n",
    "    x = 0.5 \n",
    "    x_diff = 0 # Initial uncertainty is zero\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "        \n",
    "    for i in range(Nt):\n",
    "        x_mean = logistic_map(r, x)\n",
    "        x_sigma = x_diff * sigma\n",
    "        x = logistic_map(r, x + sigma * np.random.normal())\n",
    "        x_diff = logistic_map_diff(r, x)\n",
    "        \n",
    "        time_series.append(x)\n",
    "        mean_series.append(x_mean)\n",
    "        sigma_series.append(x_sigma)\n",
    "    \n",
    "    if np.any(np.abs(np.array(time_series))>1):\n",
    "        # discard stray trajectories\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"good seed: {traj_idx-1}\")\n",
    "        counter += 1\n",
    "        \n",
    "    plt.plot(time_series, alpha = 1, lw = 0, marker = 'o')\n",
    "    plt.show()\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Map\n",
    "traj_name = 'logistic_map'\n",
    "# hyper-parameter to load from json\n",
    "\n",
    "Nt = 1000\n",
    "sigma = 0\n",
    "r = 3.9\n",
    "\n",
    "### Logistic Map\n",
    "def logistic_map(r, x):\n",
    "    return r * x * (1 - x)\n",
    "\n",
    "### Manual differentiation\n",
    "def logistic_map_diff(r, x):\n",
    "    return np.abs(r * (1-2*x))\n",
    "\n",
    "counter = -1\n",
    "traj_idx = 0\n",
    "while counter < num_series-1:\n",
    "    random_seed = traj_idx\n",
    "    np.random.seed(random_seed)\n",
    "    traj_idx += 1\n",
    "    x = np.random.uniform() * 0.7\n",
    "    x_diff = 0 # Initial uncertainty is zero\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "        \n",
    "    for i in range(Nt):\n",
    "        x_mean = logistic_map(r, x)\n",
    "        x_sigma = x_diff * sigma\n",
    "        x = logistic_map(r, x + sigma * np.random.normal())\n",
    "        x_diff = logistic_map_diff(r, x)\n",
    "        \n",
    "        time_series.append(x)\n",
    "        mean_series.append(x_mean)\n",
    "        sigma_series.append(x_sigma)\n",
    "    \n",
    "    if np.any(np.abs(np.array(time_series))>1):\n",
    "        # discard stray trajectories\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"good seed: {traj_idx-1}\")\n",
    "        counter += 1\n",
    "        \n",
    "    plt.plot(time_series, alpha = 1, lw = 0, marker = 'o')\n",
    "    plt.show()\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_name = 'lorenz_system'\n",
    "# hyper-parameter to load from json\n",
    "\n",
    "# Nt = 1000\n",
    "# Nt = 300\n",
    "Nt = 400\n",
    "tspan = np.linspace(0, 100, Nt)\n",
    "sigma = 10.0\n",
    "rho = 28.0\n",
    "beta = 8.0 / 3.0\n",
    "\n",
    "def lorenz(state, t):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x * (rho - z) - y\n",
    "    dzdt = x * y - beta * z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "counter = -1\n",
    "traj_idx = 0\n",
    "for i in range(num_series):\n",
    "    # Specific initial condition\n",
    "    \n",
    "    random_seed = i\n",
    "    np.random.seed(random_seed)\n",
    "    initial_state = [np.random.uniform()*0.3, 2.01, 23.02] \n",
    "    \n",
    "    solution = odeint(lorenz, initial_state, tspan)\n",
    "    X = solution[:, 0]\n",
    "    time_series = X.tolist()\n",
    "    mean_series = time_series\n",
    "    sigma_series = [0] * Nt\n",
    "    \n",
    "        \n",
    "    plt.plot(time_series, alpha = 1, lw = 1, marker = 'o')\n",
    "    plt.show()\n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncorrelated Gaussian\n",
    "traj_name = 'uncorrelated_gaussian'\n",
    "\n",
    "\n",
    "Nt = 1000\n",
    "sigma = 1\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx+2\n",
    "    np.random.seed(random_seed)\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "    for t in range(0, Nt):\n",
    "        W =  np.random.normal() * sigma \n",
    "        \n",
    "        time_series.append(W)\n",
    "        mean_series.append(0)\n",
    "        sigma_series.append(sigma)\n",
    "        \n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(time_series, lw = 0, marker = 'o', alpha = 1)\n",
    "    \n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncorrelated Uniform\n",
    "traj_name  = 'uncorrelated_uniform'\n",
    "# hyper-parameter to load from json\n",
    "\n",
    "Nt = 1000 \n",
    "\n",
    "sigma = 1\n",
    "for traj_idx in range(num_series):\n",
    "    random_seed = traj_idx\n",
    "    np.random.seed(random_seed)\n",
    "    time_series = []\n",
    "    mean_series = []\n",
    "    sigma_series = []\n",
    "    for t in range(0, Nt):\n",
    "        W =  np.random.uniform() * sigma \n",
    "        \n",
    "        time_series.append(W)\n",
    "        # mean_series.append(0)\n",
    "        # sigma_series.append(sigma)\n",
    "        \n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(time_series, lw = 0, marker = 'o', alpha = 1)\n",
    "    \n",
    "    full_series, rescaled_true_mean_arr, rescaled_true_sigma_arr = serialize_gaussian(prec, time_series, mean_series, sigma_series)\n",
    "    # Save the generated data to a dictionary\n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'rescaled_true_mean_arr': rescaled_true_mean_arr,\n",
    "            'rescaled_true_sigma_arr': rescaled_true_sigma_arr,\n",
    "            'prec': prec,\n",
    "            'llama_size': llama_size,\n",
    "            'mode': mode,\n",
    "            'refine_depth': refine_depth,\n",
    "            'random_seed': random_seed,\n",
    "            'time_series': np.array(time_series)\n",
    "        }\n",
    "    \n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sep = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_size_list = ['13b','13b','13b','13b','13b','13b']\n",
    "Nt_list = [1500, 1500, 1500, 1500, 1500, 1500, 1500]\n",
    "N_state_list = [4,5,6,7,8,9,10]\n",
    "random_seed_list = [1,1,1,1,1,1,1]\n",
    "\n",
    "llama_size_list += ['70b','70b','70b']\n",
    "Nt_list += [1500, 1500, 1500]\n",
    "N_state_list += [8,9,10]\n",
    "random_seed_list += [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_size_list = ['13b','13b','13b','13b','13b','13b','13b','13b','13b']\n",
    "Nt_list = [1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500]\n",
    "N_state_list = [4] * 9\n",
    "random_seed_list = [2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_name  = 'markov_chain'\n",
    "for llama_size, Nt, N_state, random_seed in zip(llama_size_list, Nt_list, \n",
    "                                                N_state_list, random_seed_list):\n",
    "    states = np.arange(N_state)\n",
    "    chain = [0]\n",
    "    np.random.seed(random_seed)\n",
    "    P = generate_transition_matrix(N_state)\n",
    "        \n",
    "    for t in range(1, Nt):\n",
    "        current_state = chain[-1]\n",
    "        next_state = np.random.choice(states, p=P[current_state])\n",
    "        chain.append(next_state)\n",
    "    \n",
    "    # Convert the chain list to a string and store it in full_series\n",
    "    full_series = \"\".join(str(x) for x in chain)\n",
    "    \n",
    "    data_dict = {\n",
    "            'full_series': full_series,\n",
    "            'full_array': np.array(chain),\n",
    "            'llama_size': llama_size,\n",
    "            \n",
    "            'random_seed': random_seed,\n",
    "            'P': P\n",
    "        }\n",
    "    # Pickle and save the dictionary\n",
    "    file_indices = [int(name[:-4].rsplit('_',1)[1]) for name in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, name)) and name.startswith(traj_name)]\n",
    "    file_indices += [-1]\n",
    "    save_name = os.path.join(save_path, f'{traj_name}_{max(file_indices)+1}.pkl')\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
